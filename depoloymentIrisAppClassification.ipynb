{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 1.1157 - acc: 0.3833 - val_loss: 1.1025 - val_acc: 0.3333\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 1.1093 - acc: 0.3167 - val_loss: 1.0985 - val_acc: 0.3333\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 1.1034 - acc: 0.3250 - val_loss: 1.0943 - val_acc: 0.3000\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 1.0970 - acc: 0.3000 - val_loss: 1.0901 - val_acc: 0.2000\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 1.0909 - acc: 0.2583 - val_loss: 1.0859 - val_acc: 0.3333\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 1.0849 - acc: 0.3583 - val_loss: 1.0817 - val_acc: 0.4000\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 1.0783 - acc: 0.4667 - val_loss: 1.0775 - val_acc: 0.4333\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 1.0721 - acc: 0.5167 - val_loss: 1.0732 - val_acc: 0.4333\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 1.0655 - acc: 0.5250 - val_loss: 1.0689 - val_acc: 0.4333\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 40us/step - loss: 1.0602 - acc: 0.5500 - val_loss: 1.0646 - val_acc: 0.4333\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 1.0530 - acc: 0.5833 - val_loss: 1.0602 - val_acc: 0.4667\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 1.0467 - acc: 0.5833 - val_loss: 1.0557 - val_acc: 0.4667\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 1.0407 - acc: 0.6000 - val_loss: 1.0513 - val_acc: 0.4667\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 1.0341 - acc: 0.6083 - val_loss: 1.0467 - val_acc: 0.4667\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 1.0271 - acc: 0.6083 - val_loss: 1.0422 - val_acc: 0.4667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 1.0206 - acc: 0.6083 - val_loss: 1.0375 - val_acc: 0.4667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 1.0139 - acc: 0.6167 - val_loss: 1.0328 - val_acc: 0.6000\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 1.0075 - acc: 0.6750 - val_loss: 1.0278 - val_acc: 0.6000\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 1.0004 - acc: 0.6750 - val_loss: 1.0227 - val_acc: 0.6000\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.9935 - acc: 0.6750 - val_loss: 1.0176 - val_acc: 0.6000\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.9865 - acc: 0.6750 - val_loss: 1.0123 - val_acc: 0.6000\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.9790 - acc: 0.6750 - val_loss: 1.0069 - val_acc: 0.6000\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.9713 - acc: 0.6750 - val_loss: 1.0015 - val_acc: 0.6000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.9645 - acc: 0.6750 - val_loss: 0.9959 - val_acc: 0.6000\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.9570 - acc: 0.6750 - val_loss: 0.9903 - val_acc: 0.6000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.9492 - acc: 0.6750 - val_loss: 0.9845 - val_acc: 0.6000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.9412 - acc: 0.6750 - val_loss: 0.9786 - val_acc: 0.6000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.9337 - acc: 0.6750 - val_loss: 0.9724 - val_acc: 0.6000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.9258 - acc: 0.6750 - val_loss: 0.9662 - val_acc: 0.6000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.9175 - acc: 0.6750 - val_loss: 0.9597 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.9092 - acc: 0.6750 - val_loss: 0.9529 - val_acc: 0.6000\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.9010 - acc: 0.6750 - val_loss: 0.9461 - val_acc: 0.6000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.8928 - acc: 0.6750 - val_loss: 0.9391 - val_acc: 0.6000\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.8841 - acc: 0.6750 - val_loss: 0.9320 - val_acc: 0.6000\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.8758 - acc: 0.6750 - val_loss: 0.9248 - val_acc: 0.6000\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.8676 - acc: 0.6750 - val_loss: 0.9177 - val_acc: 0.6000\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.8590 - acc: 0.6750 - val_loss: 0.9104 - val_acc: 0.6000\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.8508 - acc: 0.6750 - val_loss: 0.9031 - val_acc: 0.6000\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.8418 - acc: 0.6750 - val_loss: 0.8957 - val_acc: 0.6000\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.8336 - acc: 0.6750 - val_loss: 0.8883 - val_acc: 0.6000\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.8250 - acc: 0.6750 - val_loss: 0.8808 - val_acc: 0.6000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.8163 - acc: 0.6750 - val_loss: 0.8734 - val_acc: 0.6000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.8078 - acc: 0.6750 - val_loss: 0.8659 - val_acc: 0.6000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.7993 - acc: 0.6750 - val_loss: 0.8584 - val_acc: 0.6000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.7908 - acc: 0.6750 - val_loss: 0.8508 - val_acc: 0.6000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.7826 - acc: 0.6750 - val_loss: 0.8433 - val_acc: 0.6000\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.7739 - acc: 0.6750 - val_loss: 0.8359 - val_acc: 0.6000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.7660 - acc: 0.6750 - val_loss: 0.8285 - val_acc: 0.6000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.7577 - acc: 0.6750 - val_loss: 0.8211 - val_acc: 0.6000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.7496 - acc: 0.6750 - val_loss: 0.8135 - val_acc: 0.6000\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.7414 - acc: 0.6750 - val_loss: 0.8061 - val_acc: 0.6000\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.7337 - acc: 0.6750 - val_loss: 0.7988 - val_acc: 0.6000\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.7258 - acc: 0.6750 - val_loss: 0.7914 - val_acc: 0.6000\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.7180 - acc: 0.6750 - val_loss: 0.7842 - val_acc: 0.6000\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.7103 - acc: 0.6750 - val_loss: 0.7769 - val_acc: 0.6000\n",
      "Epoch 56/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.7029 - acc: 0.6750 - val_loss: 0.7697 - val_acc: 0.6000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.6955 - acc: 0.6750 - val_loss: 0.7626 - val_acc: 0.6000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.6880 - acc: 0.6750 - val_loss: 0.7555 - val_acc: 0.6000\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.6810 - acc: 0.6750 - val_loss: 0.7484 - val_acc: 0.6000\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.6739 - acc: 0.6750 - val_loss: 0.7415 - val_acc: 0.6000\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 65us/step - loss: 0.6671 - acc: 0.6750 - val_loss: 0.7347 - val_acc: 0.6000\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.6601 - acc: 0.6833 - val_loss: 0.7280 - val_acc: 0.6000\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.6533 - acc: 0.6833 - val_loss: 0.7214 - val_acc: 0.6000\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.6469 - acc: 0.6833 - val_loss: 0.7148 - val_acc: 0.6000\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.6402 - acc: 0.6833 - val_loss: 0.7084 - val_acc: 0.6000\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 90us/step - loss: 0.6338 - acc: 0.6833 - val_loss: 0.7022 - val_acc: 0.6000\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.6277 - acc: 0.6833 - val_loss: 0.6958 - val_acc: 0.6333\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5766 - acc: 0.750 - 0s 89us/step - loss: 0.6214 - acc: 0.6833 - val_loss: 0.6896 - val_acc: 0.6333\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.6155 - acc: 0.7000 - val_loss: 0.6835 - val_acc: 0.6333\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.6094 - acc: 0.7000 - val_loss: 0.6773 - val_acc: 0.6333\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.6037 - acc: 0.7167 - val_loss: 0.6713 - val_acc: 0.6333\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5978 - acc: 0.7167 - val_loss: 0.6654 - val_acc: 0.6333\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5922 - acc: 0.7167 - val_loss: 0.6595 - val_acc: 0.6333\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5867 - acc: 0.7333 - val_loss: 0.6537 - val_acc: 0.6333\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5813 - acc: 0.7417 - val_loss: 0.6480 - val_acc: 0.6333\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5760 - acc: 0.7500 - val_loss: 0.6424 - val_acc: 0.6667\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5708 - acc: 0.7500 - val_loss: 0.6368 - val_acc: 0.6667\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5656 - acc: 0.7500 - val_loss: 0.6315 - val_acc: 0.6667\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5606 - acc: 0.7500 - val_loss: 0.6261 - val_acc: 0.7000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5558 - acc: 0.7500 - val_loss: 0.6208 - val_acc: 0.7000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5509 - acc: 0.7500 - val_loss: 0.6157 - val_acc: 0.7333\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5461 - acc: 0.7500 - val_loss: 0.6106 - val_acc: 0.7333\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5414 - acc: 0.7500 - val_loss: 0.6055 - val_acc: 0.7333\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.5369 - acc: 0.7500 - val_loss: 0.6005 - val_acc: 0.7333\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.5324 - acc: 0.7500 - val_loss: 0.5955 - val_acc: 0.7333\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.5279 - acc: 0.7500 - val_loss: 0.5906 - val_acc: 0.7667\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.5236 - acc: 0.7500 - val_loss: 0.5857 - val_acc: 0.7667\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5193 - acc: 0.7583 - val_loss: 0.5809 - val_acc: 0.7667\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.5150 - acc: 0.7667 - val_loss: 0.5762 - val_acc: 0.7667\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.5109 - acc: 0.7667 - val_loss: 0.5715 - val_acc: 0.7667\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.5068 - acc: 0.7667 - val_loss: 0.5670 - val_acc: 0.7667\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.5028 - acc: 0.7750 - val_loss: 0.5625 - val_acc: 0.7667\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.4989 - acc: 0.7750 - val_loss: 0.5581 - val_acc: 0.7667\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.4950 - acc: 0.7750 - val_loss: 0.5537 - val_acc: 0.7667\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 98us/step - loss: 0.4912 - acc: 0.7750 - val_loss: 0.5494 - val_acc: 0.7667\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.4874 - acc: 0.7833 - val_loss: 0.5451 - val_acc: 0.7667\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.4838 - acc: 0.7833 - val_loss: 0.5408 - val_acc: 0.7667\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.4800 - acc: 0.7833 - val_loss: 0.5367 - val_acc: 0.7667\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.4765 - acc: 0.7833 - val_loss: 0.5326 - val_acc: 0.7667\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.4729 - acc: 0.7833 - val_loss: 0.5286 - val_acc: 0.7667\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.4694 - acc: 0.7833 - val_loss: 0.5246 - val_acc: 0.7667\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.4661 - acc: 0.7833 - val_loss: 0.5205 - val_acc: 0.7667\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.4627 - acc: 0.7833 - val_loss: 0.5165 - val_acc: 0.7667\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.4593 - acc: 0.7833 - val_loss: 0.5125 - val_acc: 0.7667\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.4559 - acc: 0.8000 - val_loss: 0.5086 - val_acc: 0.7667\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.4528 - acc: 0.8000 - val_loss: 0.5047 - val_acc: 0.7667\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.4494 - acc: 0.8000 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.4462 - acc: 0.8000 - val_loss: 0.4973 - val_acc: 0.8000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.4431 - acc: 0.8083 - val_loss: 0.4936 - val_acc: 0.8000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.4399 - acc: 0.8083 - val_loss: 0.4900 - val_acc: 0.8000\n",
      "Epoch 111/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.4369 - acc: 0.8083 - val_loss: 0.4862 - val_acc: 0.8000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.4341 - acc: 0.8083 - val_loss: 0.4825 - val_acc: 0.8333\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.4309 - acc: 0.8083 - val_loss: 0.4789 - val_acc: 0.8333\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.4279 - acc: 0.8083 - val_loss: 0.4753 - val_acc: 0.8333\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.4250 - acc: 0.8083 - val_loss: 0.4719 - val_acc: 0.8333\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.4221 - acc: 0.8167 - val_loss: 0.4685 - val_acc: 0.8333\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.4193 - acc: 0.8250 - val_loss: 0.4651 - val_acc: 0.8333\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.4164 - acc: 0.8333 - val_loss: 0.4618 - val_acc: 0.8333\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.4137 - acc: 0.8333 - val_loss: 0.4584 - val_acc: 0.8333\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.4110 - acc: 0.8333 - val_loss: 0.4551 - val_acc: 0.8333\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 73us/step - loss: 0.4082 - acc: 0.8333 - val_loss: 0.4519 - val_acc: 0.8333\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.4055 - acc: 0.8333 - val_loss: 0.4486 - val_acc: 0.8667\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.4029 - acc: 0.8333 - val_loss: 0.4454 - val_acc: 0.9000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.4002 - acc: 0.8333 - val_loss: 0.4422 - val_acc: 0.9000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3977 - acc: 0.8333 - val_loss: 0.4390 - val_acc: 0.9000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3950 - acc: 0.8333 - val_loss: 0.4359 - val_acc: 0.9000\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3925 - acc: 0.8333 - val_loss: 0.4329 - val_acc: 0.9000\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3900 - acc: 0.8333 - val_loss: 0.4299 - val_acc: 0.9000\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3875 - acc: 0.8333 - val_loss: 0.4269 - val_acc: 0.9000\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3851 - acc: 0.8417 - val_loss: 0.4238 - val_acc: 0.9000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3826 - acc: 0.8417 - val_loss: 0.4209 - val_acc: 0.9000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3802 - acc: 0.8417 - val_loss: 0.4180 - val_acc: 0.9000\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3302 - acc: 0.906 - 0s 41us/step - loss: 0.3777 - acc: 0.8500 - val_loss: 0.4151 - val_acc: 0.9000\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3754 - acc: 0.8500 - val_loss: 0.4122 - val_acc: 0.9000\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3730 - acc: 0.8417 - val_loss: 0.4092 - val_acc: 0.9000\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3708 - acc: 0.8500 - val_loss: 0.4063 - val_acc: 0.9333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3683 - acc: 0.8500 - val_loss: 0.4035 - val_acc: 0.9333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.3661 - acc: 0.8500 - val_loss: 0.4007 - val_acc: 0.9333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3638 - acc: 0.8500 - val_loss: 0.3979 - val_acc: 0.9333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3616 - acc: 0.8500 - val_loss: 0.3951 - val_acc: 0.9333\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3593 - acc: 0.8500 - val_loss: 0.3924 - val_acc: 0.9667\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3571 - acc: 0.8500 - val_loss: 0.3897 - val_acc: 0.9667\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3548 - acc: 0.8500 - val_loss: 0.3870 - val_acc: 0.9667\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.3527 - acc: 0.8583 - val_loss: 0.3843 - val_acc: 0.9667\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.3505 - acc: 0.8667 - val_loss: 0.3817 - val_acc: 0.9667\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3484 - acc: 0.8750 - val_loss: 0.3791 - val_acc: 0.9667\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3464 - acc: 0.8750 - val_loss: 0.3765 - val_acc: 0.9667\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3443 - acc: 0.8833 - val_loss: 0.3738 - val_acc: 0.9667\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3422 - acc: 0.8750 - val_loss: 0.3713 - val_acc: 0.9667\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3401 - acc: 0.8750 - val_loss: 0.3687 - val_acc: 0.9667\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3380 - acc: 0.8750 - val_loss: 0.3663 - val_acc: 0.9667\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3360 - acc: 0.8750 - val_loss: 0.3638 - val_acc: 0.9667\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3341 - acc: 0.8750 - val_loss: 0.3614 - val_acc: 0.9667\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3322 - acc: 0.8750 - val_loss: 0.3589 - val_acc: 0.9667\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3301 - acc: 0.8833 - val_loss: 0.3565 - val_acc: 0.9667\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3282 - acc: 0.8833 - val_loss: 0.3542 - val_acc: 0.9667\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3265 - acc: 0.9000 - val_loss: 0.3518 - val_acc: 0.9667\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3244 - acc: 0.9000 - val_loss: 0.3495 - val_acc: 0.9667\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3226 - acc: 0.9083 - val_loss: 0.3472 - val_acc: 0.9667\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3207 - acc: 0.9083 - val_loss: 0.3450 - val_acc: 0.9667\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3192 - acc: 0.9083 - val_loss: 0.3427 - val_acc: 0.9667\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3170 - acc: 0.9083 - val_loss: 0.3405 - val_acc: 0.9667\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.3153 - acc: 0.9083 - val_loss: 0.3383 - val_acc: 0.9667\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.3135 - acc: 0.9083 - val_loss: 0.3361 - val_acc: 0.9667\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3117 - acc: 0.9083 - val_loss: 0.3340 - val_acc: 0.9667\n",
      "Epoch 166/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.3101 - acc: 0.9083 - val_loss: 0.3318 - val_acc: 0.9667\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.3083 - acc: 0.9083 - val_loss: 0.3297 - val_acc: 0.9667\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.3067 - acc: 0.9167 - val_loss: 0.3276 - val_acc: 0.9667\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.3049 - acc: 0.9167 - val_loss: 0.3255 - val_acc: 0.9667\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3032 - acc: 0.9167 - val_loss: 0.3235 - val_acc: 0.9667\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.3015 - acc: 0.9167 - val_loss: 0.3214 - val_acc: 0.9667\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2999 - acc: 0.9167 - val_loss: 0.3194 - val_acc: 0.9667\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2983 - acc: 0.9167 - val_loss: 0.3174 - val_acc: 0.9667\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2966 - acc: 0.9167 - val_loss: 0.3155 - val_acc: 0.9667\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2950 - acc: 0.9167 - val_loss: 0.3136 - val_acc: 0.9667\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2934 - acc: 0.9167 - val_loss: 0.3116 - val_acc: 0.9667\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2919 - acc: 0.9167 - val_loss: 0.3097 - val_acc: 0.9667\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2903 - acc: 0.9167 - val_loss: 0.3078 - val_acc: 0.9667\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2888 - acc: 0.9167 - val_loss: 0.3059 - val_acc: 1.0000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2873 - acc: 0.9250 - val_loss: 0.3040 - val_acc: 1.0000\n",
      "Epoch 181/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 49us/step - loss: 0.2857 - acc: 0.9250 - val_loss: 0.3023 - val_acc: 1.0000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2842 - acc: 0.9250 - val_loss: 0.3004 - val_acc: 1.0000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2830 - acc: 0.9250 - val_loss: 0.2986 - val_acc: 1.0000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2813 - acc: 0.9250 - val_loss: 0.2968 - val_acc: 1.0000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2799 - acc: 0.9250 - val_loss: 0.2951 - val_acc: 1.0000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2783 - acc: 0.9250 - val_loss: 0.2933 - val_acc: 1.0000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2769 - acc: 0.9250 - val_loss: 0.2916 - val_acc: 1.0000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2755 - acc: 0.9250 - val_loss: 0.2899 - val_acc: 1.0000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2741 - acc: 0.9250 - val_loss: 0.2881 - val_acc: 1.0000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2726 - acc: 0.9250 - val_loss: 0.2864 - val_acc: 1.0000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2712 - acc: 0.9250 - val_loss: 0.2848 - val_acc: 1.0000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2699 - acc: 0.9250 - val_loss: 0.2831 - val_acc: 1.0000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2685 - acc: 0.9250 - val_loss: 0.2814 - val_acc: 1.0000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2672 - acc: 0.9250 - val_loss: 0.2798 - val_acc: 1.0000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2658 - acc: 0.9250 - val_loss: 0.2781 - val_acc: 1.0000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2646 - acc: 0.9250 - val_loss: 0.2765 - val_acc: 1.0000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.2632 - acc: 0.9250 - val_loss: 0.2748 - val_acc: 1.0000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2620 - acc: 0.9250 - val_loss: 0.2732 - val_acc: 1.0000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2607 - acc: 0.9333 - val_loss: 0.2717 - val_acc: 1.0000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2593 - acc: 0.9333 - val_loss: 0.2702 - val_acc: 1.0000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2580 - acc: 0.9333 - val_loss: 0.2688 - val_acc: 1.0000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2568 - acc: 0.9333 - val_loss: 0.2674 - val_acc: 1.0000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2555 - acc: 0.9333 - val_loss: 0.2659 - val_acc: 1.0000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2544 - acc: 0.9333 - val_loss: 0.2643 - val_acc: 1.0000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2532 - acc: 0.9333 - val_loss: 0.2629 - val_acc: 1.0000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2519 - acc: 0.9333 - val_loss: 0.2614 - val_acc: 1.0000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2508 - acc: 0.9333 - val_loss: 0.2600 - val_acc: 1.0000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2495 - acc: 0.9333 - val_loss: 0.2585 - val_acc: 1.0000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2483 - acc: 0.9333 - val_loss: 0.2571 - val_acc: 1.0000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2471 - acc: 0.9333 - val_loss: 0.2557 - val_acc: 1.0000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2460 - acc: 0.9333 - val_loss: 0.2542 - val_acc: 1.0000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2448 - acc: 0.9333 - val_loss: 0.2528 - val_acc: 1.0000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2438 - acc: 0.9333 - val_loss: 0.2516 - val_acc: 1.0000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2425 - acc: 0.9333 - val_loss: 0.2503 - val_acc: 1.0000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2414 - acc: 0.9333 - val_loss: 0.2489 - val_acc: 1.0000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2402 - acc: 0.9333 - val_loss: 0.2476 - val_acc: 1.0000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2392 - acc: 0.9333 - val_loss: 0.2462 - val_acc: 1.0000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2381 - acc: 0.9333 - val_loss: 0.2449 - val_acc: 1.0000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2370 - acc: 0.9333 - val_loss: 0.2435 - val_acc: 1.0000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2359 - acc: 0.9333 - val_loss: 0.2422 - val_acc: 1.0000\n",
      "Epoch 221/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2348 - acc: 0.9333 - val_loss: 0.2409 - val_acc: 1.0000\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2338 - acc: 0.9333 - val_loss: 0.2397 - val_acc: 1.0000\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2326 - acc: 0.9333 - val_loss: 0.2383 - val_acc: 1.0000\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2316 - acc: 0.9333 - val_loss: 0.2372 - val_acc: 1.0000\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.2306 - acc: 0.9333 - val_loss: 0.2359 - val_acc: 1.0000\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2295 - acc: 0.9333 - val_loss: 0.2345 - val_acc: 1.0000\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2285 - acc: 0.9333 - val_loss: 0.2332 - val_acc: 1.0000\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.2275 - acc: 0.9333 - val_loss: 0.2320 - val_acc: 1.0000\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2264 - acc: 0.9333 - val_loss: 0.2307 - val_acc: 1.0000\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2254 - acc: 0.9417 - val_loss: 0.2295 - val_acc: 1.0000\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1825 - acc: 1.000 - 0s 57us/step - loss: 0.2244 - acc: 0.9417 - val_loss: 0.2282 - val_acc: 1.0000\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2234 - acc: 0.9417 - val_loss: 0.2271 - val_acc: 1.0000\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2225 - acc: 0.9417 - val_loss: 0.2259 - val_acc: 1.0000\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2215 - acc: 0.9417 - val_loss: 0.2247 - val_acc: 1.0000\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2205 - acc: 0.9417 - val_loss: 0.2236 - val_acc: 1.0000\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2195 - acc: 0.9417 - val_loss: 0.2223 - val_acc: 1.0000\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2186 - acc: 0.9417 - val_loss: 0.2212 - val_acc: 1.0000\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2177 - acc: 0.9417 - val_loss: 0.2202 - val_acc: 1.0000\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2167 - acc: 0.9417 - val_loss: 0.2191 - val_acc: 1.0000\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2157 - acc: 0.9417 - val_loss: 0.2180 - val_acc: 1.0000\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 57us/step - loss: 0.2149 - acc: 0.9417 - val_loss: 0.2171 - val_acc: 1.0000\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2139 - acc: 0.9417 - val_loss: 0.2161 - val_acc: 1.0000\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2129 - acc: 0.9417 - val_loss: 0.2149 - val_acc: 1.0000\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2122 - acc: 0.9417 - val_loss: 0.2140 - val_acc: 1.0000\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2112 - acc: 0.9333 - val_loss: 0.2128 - val_acc: 1.0000\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2103 - acc: 0.9333 - val_loss: 0.2117 - val_acc: 1.0000\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2094 - acc: 0.9333 - val_loss: 0.2108 - val_acc: 1.0000\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2085 - acc: 0.9333 - val_loss: 0.2097 - val_acc: 1.0000\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2076 - acc: 0.9333 - val_loss: 0.2088 - val_acc: 1.0000\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.2067 - acc: 0.9333 - val_loss: 0.2077 - val_acc: 1.0000\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2060 - acc: 0.9333 - val_loss: 0.2065 - val_acc: 1.0000\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2051 - acc: 0.9333 - val_loss: 0.2057 - val_acc: 1.0000\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.2042 - acc: 0.9333 - val_loss: 0.2048 - val_acc: 1.0000\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2034 - acc: 0.9333 - val_loss: 0.2039 - val_acc: 1.0000\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2025 - acc: 0.9333 - val_loss: 0.2029 - val_acc: 1.0000\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2017 - acc: 0.9333 - val_loss: 0.2020 - val_acc: 1.0000\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.2008 - acc: 0.9333 - val_loss: 0.2010 - val_acc: 1.0000\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.2000 - acc: 0.9333 - val_loss: 0.2002 - val_acc: 1.0000\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1992 - acc: 0.9333 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1984 - acc: 0.9333 - val_loss: 0.1982 - val_acc: 1.0000\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1976 - acc: 0.9333 - val_loss: 0.1974 - val_acc: 1.0000\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1967 - acc: 0.9333 - val_loss: 0.1965 - val_acc: 1.0000\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1959 - acc: 0.9333 - val_loss: 0.1959 - val_acc: 1.0000\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1951 - acc: 0.9333 - val_loss: 0.1950 - val_acc: 1.0000\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1943 - acc: 0.9333 - val_loss: 0.1941 - val_acc: 1.0000\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1935 - acc: 0.9333 - val_loss: 0.1931 - val_acc: 1.0000\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1928 - acc: 0.9333 - val_loss: 0.1924 - val_acc: 1.0000\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1920 - acc: 0.9333 - val_loss: 0.1916 - val_acc: 1.0000\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1912 - acc: 0.9333 - val_loss: 0.1907 - val_acc: 1.0000\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1904 - acc: 0.9417 - val_loss: 0.1898 - val_acc: 1.0000\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1896 - acc: 0.9417 - val_loss: 0.1889 - val_acc: 1.0000\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1889 - acc: 0.9417 - val_loss: 0.1882 - val_acc: 1.0000\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1881 - acc: 0.9417 - val_loss: 0.1873 - val_acc: 1.0000\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1874 - acc: 0.9417 - val_loss: 0.1864 - val_acc: 1.0000\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1867 - acc: 0.9417 - val_loss: 0.1858 - val_acc: 1.0000\n",
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1859 - acc: 0.9417 - val_loss: 0.1849 - val_acc: 1.0000\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1852 - acc: 0.9417 - val_loss: 0.1842 - val_acc: 1.0000\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1844 - acc: 0.9417 - val_loss: 0.1832 - val_acc: 1.0000\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1837 - acc: 0.9417 - val_loss: 0.1823 - val_acc: 1.0000\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1829 - acc: 0.9417 - val_loss: 0.1814 - val_acc: 1.0000\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1823 - acc: 0.9417 - val_loss: 0.1804 - val_acc: 1.0000\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1815 - acc: 0.9417 - val_loss: 0.1797 - val_acc: 1.0000\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1808 - acc: 0.9500 - val_loss: 0.1790 - val_acc: 1.0000\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1801 - acc: 0.9500 - val_loss: 0.1784 - val_acc: 1.0000\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1793 - acc: 0.9500 - val_loss: 0.1777 - val_acc: 1.0000\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2027 - acc: 0.937 - 0s 57us/step - loss: 0.1786 - acc: 0.9500 - val_loss: 0.1768 - val_acc: 1.0000\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1781 - acc: 0.9500 - val_loss: 0.1764 - val_acc: 1.0000\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1773 - acc: 0.9500 - val_loss: 0.1754 - val_acc: 1.0000\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1766 - acc: 0.9583 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1759 - acc: 0.9583 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1752 - acc: 0.9583 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 81us/step - loss: 0.1745 - acc: 0.9583 - val_loss: 0.1726 - val_acc: 1.0000\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1739 - acc: 0.9583 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 73us/step - loss: 0.1733 - acc: 0.9583 - val_loss: 0.1714 - val_acc: 1.0000\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1725 - acc: 0.9583 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1719 - acc: 0.9583 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1712 - acc: 0.9583 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 65us/step - loss: 0.1706 - acc: 0.9583 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 89us/step - loss: 0.1699 - acc: 0.9583 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 57us/step - loss: 0.1693 - acc: 0.9583 - val_loss: 0.1668 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28ad5bb5668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "iris = pd.read_csv('./iris.csv')\n",
    "iris.head()\n",
    "x = iris.drop('species',axis=1)\n",
    "y = iris['species']\n",
    "\n",
    "#encoding y\n",
    "from sklearn .preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)\n",
    "y\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=101)\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = Sequential()\n",
    "model.add(Dense(units= 4,input_shape=[4,],activation='relu'))\n",
    "model.add(Dense(units= 3, kernel_initializer='normal', activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(patience=10)\n",
    "\n",
    "model.fit(x=x_train,y=y_train,epochs=300,\n",
    "         validation_data=(x_test,y_test),callbacks=[early_stop])\n",
    "\n",
    "\n",
    "#iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28ad59065f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics\n",
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28ad59a6710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['acc','val_acc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16684027016162872, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test,verbose=0) # final loss against final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
